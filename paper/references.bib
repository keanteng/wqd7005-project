@misc{huang2020tabtransformertabulardatamodeling,
      title={TabTransformer: Tabular Data Modeling Using Contextual Embeddings}, 
      author={Xin Huang and Ashish Khetan and Milan Cvitkovic and Zohar Karnin},
      year={2020},
      eprint={2012.06678},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2012.06678}, 
}

@misc{gorishniy2023revisitingdeeplearningmodels,
      title={Revisiting Deep Learning Models for Tabular Data}, 
      author={Yury Gorishniy and Ivan Rubachev and Valentin Khrulkov and Artem Babenko},
      year={2023},
      eprint={2106.11959},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.11959}, 
}

@article{Lee_2019,
   title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
   volume={36},
   ISSN={1367-4811},
   url={http://dx.doi.org/10.1093/bioinformatics/btz682},
   DOI={10.1093/bioinformatics/btz682},
   number={4},
   journal={Bioinformatics},
   publisher={Oxford University Press (OUP)},
   author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
   editor={Wren, Jonathan},
   year={2019},
   month=sep, pages={1234–1240} }

@misc{ling2023bioclinicalbertbertbase,
      title={Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for Predicting Drug-Review Satisfaction}, 
      author={Yue Ling},
      year={2023},
      eprint={2308.03782},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.03782}, 
}

@misc{devlin2019bertpretrainingdeepbidirectional,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

@misc{Doshi_2025, 
      title={Gemini 2.5: Our most intelligent models are getting even better}, 
      url={https://blog.google/technology/google-deepmind/google-gemini-updates-io-2025/#developer-experience}, 
      journal={Google}, 
      publisher={Google}, 
      author={Doshi, Tulsee}, 
      year={2025}, 
      month={May}
}

@misc{xGrokBeta,
	author = {XAI},
	title = {{G}rok 3 {B}eta — {T}he {A}ge of {R}easoning {A}gents | x{A}{I} --- x.ai},
	url= {https://x.ai/news/grok-3},
      publisher = {xAI},
	year = {2025},
      month = {Feb}
}