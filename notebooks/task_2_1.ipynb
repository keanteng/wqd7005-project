{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1c9891",
   "metadata": {},
   "source": [
    "# Part 2 - Predictive Model Development\n",
    "\n",
    "## Section 1: Developing Classification Models\n",
    "\n",
    "In this section, we will perform classification on the simulated patients data using various machine learning models. We will also look into NLP tasks such as sentiment analysis, classification, and clinical text interpretation using specialized language models (SLMs).\n",
    "\n",
    "## Assignment Details\n",
    "- Author: Khor Kean Teng\n",
    "- Date: May 23, 2025\n",
    "- Model: Gemini 2.5 Flash Preview-0520\n",
    "\n",
    "## Deliverables\n",
    "- Construct and evaluate predictive models, including traditional models (Random Forest, XGBoost, Neural Networks) and advanced Transformer-based models. \n",
    "- Use SLMs for specialized NLP tasks like sentiment analysis, clinical text interpretation, and classification of questionnaire responses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db917613",
   "metadata": {},
   "source": [
    "## 1.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd902487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>medical_history</th>\n",
       "      <th>deterioration_label</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hear_rate</th>\n",
       "      <th>blood_pressure_sys</th>\n",
       "      <th>blood_pressure_dia</th>\n",
       "      <th>oxygen_saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>has_cancer</th>\n",
       "      <th>has_heart attack</th>\n",
       "      <th>has_heart failure</th>\n",
       "      <th>has_copd</th>\n",
       "      <th>has_asthma</th>\n",
       "      <th>has_alzheimer</th>\n",
       "      <th>has_dementia</th>\n",
       "      <th>fatigue_level</th>\n",
       "      <th>activity_level</th>\n",
       "      <th>mental_health_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9b04b</td>\n",
       "      <td>65</td>\n",
       "      <td>Male</td>\n",
       "      <td>History of hypertension and type 2 diabetes.</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-10-27T10:00:00Z</td>\n",
       "      <td>95.5</td>\n",
       "      <td>160.2</td>\n",
       "      <td>98.7</td>\n",
       "      <td>90.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bffd5</td>\n",
       "      <td>45</td>\n",
       "      <td>Female</td>\n",
       "      <td>No significant medical history.</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-10-27T10:05:00Z</td>\n",
       "      <td>70.2</td>\n",
       "      <td>120.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fb35e</td>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chronic obstructive pulmonary disease (COPD), ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-10-27T10:10:00Z</td>\n",
       "      <td>105.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e30e</td>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>Mild asthma.</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-10-27T10:15:00Z</td>\n",
       "      <td>65.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116a4</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>High cholesterol.</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-10-27T10:20:00Z</td>\n",
       "      <td>75.5</td>\n",
       "      <td>135.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id  age  gender                                    medical_history  \\\n",
       "0      9b04b   65    Male       History of hypertension and type 2 diabetes.   \n",
       "1      bffd5   45  Female                    No significant medical history.   \n",
       "2      fb35e   78    Male  Chronic obstructive pulmonary disease (COPD), ...   \n",
       "3      1e30e   30  Female                                       Mild asthma.   \n",
       "4      116a4   55    Male                                  High cholesterol.   \n",
       "\n",
       "   deterioration_label             timestamp  hear_rate  blood_pressure_sys  \\\n",
       "0                 True  2023-10-27T10:00:00Z       95.5               160.2   \n",
       "1                False  2023-10-27T10:05:00Z       70.2               120.5   \n",
       "2                 True  2023-10-27T10:10:00Z      105.0               150.0   \n",
       "3                False  2023-10-27T10:15:00Z       65.0               110.0   \n",
       "4                False  2023-10-27T10:20:00Z       75.5               135.0   \n",
       "\n",
       "   blood_pressure_dia  oxygen_saturation  ...  has_cancer  has_heart attack  \\\n",
       "0                98.7               90.3  ...           0                 0   \n",
       "1                75.0               98.5  ...           0                 0   \n",
       "2                90.0               88.0  ...           0                 1   \n",
       "3                70.0               99.0  ...           0                 0   \n",
       "4                85.0               97.0  ...           0                 0   \n",
       "\n",
       "  has_heart failure has_copd has_asthma has_alzheimer  has_dementia  \\\n",
       "0                 0        0          0             0             0   \n",
       "1                 0        0          0             0             0   \n",
       "2                 0        1          0             0             0   \n",
       "3                 0        0          1             0             0   \n",
       "4                 0        0          0             0             0   \n",
       "\n",
       "   fatigue_level  activity_level  mental_health_level  \n",
       "0              5               1                    1  \n",
       "1              2               4                    4  \n",
       "2              5               2                    1  \n",
       "3              1               5                    4  \n",
       "4              3               3                    3  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# read the CSV file\n",
    "df = pd.read_csv('data/processed/patients_with_ratings.csv')\n",
    "\n",
    "# preview the data\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea383d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>deterioration_label</th>\n",
       "      <th>hear_rate</th>\n",
       "      <th>blood_pressure_sys</th>\n",
       "      <th>blood_pressure_dia</th>\n",
       "      <th>oxygen_saturation</th>\n",
       "      <th>temperature</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>has_stroke</th>\n",
       "      <th>...</th>\n",
       "      <th>has_cancer</th>\n",
       "      <th>has_heart attack</th>\n",
       "      <th>has_heart failure</th>\n",
       "      <th>has_copd</th>\n",
       "      <th>has_asthma</th>\n",
       "      <th>has_alzheimer</th>\n",
       "      <th>has_dementia</th>\n",
       "      <th>fatigue_level</th>\n",
       "      <th>activity_level</th>\n",
       "      <th>mental_health_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>95.5</td>\n",
       "      <td>160.2</td>\n",
       "      <td>98.7</td>\n",
       "      <td>90.3</td>\n",
       "      <td>38.5</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>70.2</td>\n",
       "      <td>120.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>105.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>37.9</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>65.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>75.5</td>\n",
       "      <td>135.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  deterioration_label  hear_rate  blood_pressure_sys  \\\n",
       "0   65    Male                 True       95.5               160.2   \n",
       "1   45  Female                False       70.2               120.5   \n",
       "2   78    Male                 True      105.0               150.0   \n",
       "3   30  Female                False       65.0               110.0   \n",
       "4   55    Male                False       75.5               135.0   \n",
       "\n",
       "   blood_pressure_dia  oxygen_saturation  temperature  respiratory_rate  \\\n",
       "0                98.7               90.3         38.5              22.1   \n",
       "1                75.0               98.5         36.8              16.0   \n",
       "2                90.0               88.0         37.9              25.5   \n",
       "3                70.0               99.0         36.5              14.0   \n",
       "4                85.0               97.0         37.0              17.0   \n",
       "\n",
       "   has_stroke  ...  has_cancer  has_heart attack  has_heart failure  has_copd  \\\n",
       "0           0  ...           0                 0                  0         0   \n",
       "1           0  ...           0                 0                  0         0   \n",
       "2           0  ...           0                 1                  0         1   \n",
       "3           0  ...           0                 0                  0         0   \n",
       "4           0  ...           0                 0                  0         0   \n",
       "\n",
       "   has_asthma  has_alzheimer  has_dementia  fatigue_level  activity_level  \\\n",
       "0           0              0             0              5               1   \n",
       "1           0              0             0              2               4   \n",
       "2           0              0             0              5               2   \n",
       "3           1              0             0              1               5   \n",
       "4           0              0             0              3               3   \n",
       "\n",
       "   mental_health_level  \n",
       "0                    1  \n",
       "1                    4  \n",
       "2                    1  \n",
       "3                    4  \n",
       "4                    3  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# exclude column\n",
    "exclude_columns = ['patient_id', 'timestamp', 'medical_history', 'describe_fatigue_level', 'describe_lifestyle', 'describe_mental_health', 'extracted_diseases']\n",
    "\n",
    "# prepare the data\n",
    "df = df.drop(columns=exclude_columns)\n",
    "\n",
    "# preview the data\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a14c395",
   "metadata": {},
   "source": [
    "We have removed unwanted columns and rows from the dataset. The data is now clean and ready for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abaafc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender mapping: {'Female': 0, 'Male': 1, 'Other': 2}\n",
      "\n",
      "Updated data types:\n",
      "age                      int64\n",
      "gender                   int32\n",
      "deterioration_label      int32\n",
      "hear_rate              float64\n",
      "blood_pressure_sys     float64\n",
      "blood_pressure_dia     float64\n",
      "oxygen_saturation      float64\n",
      "temperature            float64\n",
      "respiratory_rate       float64\n",
      "has_stroke               int64\n",
      "has_diabetes             int64\n",
      "has_hypertension         int64\n",
      "has_cancer               int64\n",
      "has_heart attack         int64\n",
      "has_heart failure        int64\n",
      "has_copd                 int64\n",
      "has_asthma               int64\n",
      "has_alzheimer            int64\n",
      "has_dementia             int64\n",
      "fatigue_level            int64\n",
      "activity_level           int64\n",
      "mental_health_level      int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>deterioration_label</th>\n",
       "      <th>hear_rate</th>\n",
       "      <th>blood_pressure_sys</th>\n",
       "      <th>blood_pressure_dia</th>\n",
       "      <th>oxygen_saturation</th>\n",
       "      <th>temperature</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>has_stroke</th>\n",
       "      <th>...</th>\n",
       "      <th>has_cancer</th>\n",
       "      <th>has_heart attack</th>\n",
       "      <th>has_heart failure</th>\n",
       "      <th>has_copd</th>\n",
       "      <th>has_asthma</th>\n",
       "      <th>has_alzheimer</th>\n",
       "      <th>has_dementia</th>\n",
       "      <th>fatigue_level</th>\n",
       "      <th>activity_level</th>\n",
       "      <th>mental_health_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95.5</td>\n",
       "      <td>160.2</td>\n",
       "      <td>98.7</td>\n",
       "      <td>90.3</td>\n",
       "      <td>38.5</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.2</td>\n",
       "      <td>120.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>37.9</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.5</td>\n",
       "      <td>135.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  deterioration_label  hear_rate  blood_pressure_sys  \\\n",
       "0   65       1                    1       95.5               160.2   \n",
       "1   45       0                    0       70.2               120.5   \n",
       "2   78       1                    1      105.0               150.0   \n",
       "3   30       0                    0       65.0               110.0   \n",
       "4   55       1                    0       75.5               135.0   \n",
       "\n",
       "   blood_pressure_dia  oxygen_saturation  temperature  respiratory_rate  \\\n",
       "0                98.7               90.3         38.5              22.1   \n",
       "1                75.0               98.5         36.8              16.0   \n",
       "2                90.0               88.0         37.9              25.5   \n",
       "3                70.0               99.0         36.5              14.0   \n",
       "4                85.0               97.0         37.0              17.0   \n",
       "\n",
       "   has_stroke  ...  has_cancer  has_heart attack  has_heart failure  has_copd  \\\n",
       "0           0  ...           0                 0                  0         0   \n",
       "1           0  ...           0                 0                  0         0   \n",
       "2           0  ...           0                 1                  0         1   \n",
       "3           0  ...           0                 0                  0         0   \n",
       "4           0  ...           0                 0                  0         0   \n",
       "\n",
       "   has_asthma  has_alzheimer  has_dementia  fatigue_level  activity_level  \\\n",
       "0           0              0             0              5               1   \n",
       "1           0              0             0              2               4   \n",
       "2           0              0             0              5               2   \n",
       "3           1              0             0              1               5   \n",
       "4           0              0             0              3               3   \n",
       "\n",
       "   mental_health_level  \n",
       "0                    1  \n",
       "1                    4  \n",
       "2                    1  \n",
       "3                    4  \n",
       "4                    3  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert gender (categorical) and deterioration_label (boolean) to numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Convert gender (object type) to numerical\n",
    "df['gender'] = le.fit_transform(df['gender'])\n",
    "print(f\"Gender mapping: {dict(zip(le.classes_, range(len(le.classes_))))}\")\n",
    "\n",
    "# Convert deterioration_label (boolean) to integer (0/1)\n",
    "df['deterioration_label'] = df['deterioration_label'].astype(int)\n",
    "\n",
    "# Verify the conversions\n",
    "print(\"\\nUpdated data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Preview the transformed data\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f0c532c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                      int64\n",
       "gender                   int32\n",
       "deterioration_label      int32\n",
       "hear_rate              float64\n",
       "blood_pressure_sys     float64\n",
       "blood_pressure_dia     float64\n",
       "oxygen_saturation      float64\n",
       "temperature            float64\n",
       "respiratory_rate       float64\n",
       "has_stroke               int64\n",
       "has_diabetes             int64\n",
       "has_hypertension         int64\n",
       "has_cancer               int64\n",
       "has_heart attack         int64\n",
       "has_heart failure        int64\n",
       "has_copd                 int64\n",
       "has_asthma               int64\n",
       "has_alzheimer            int64\n",
       "has_dementia             int64\n",
       "fatigue_level            int64\n",
       "activity_level           int64\n",
       "mental_health_level      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543c33f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d982855",
   "metadata": {},
   "source": [
    "We also check the data types to make sure they are appropriate for the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e124f19",
   "metadata": {},
   "source": [
    "## 2.2 Model Development - Classification\n",
    "\n",
    "In the machine learning stage, we will perform classification one the `deterioration_label` column. We will make use of Random Forest, XGBoost and Neural Networks model from the `sklearn` and `xgboost` libraries. Furthermore, we also explore the use of transformer-based model for classification tasks. In particular, we make use of `TabTransformer` model which proposed the application of attention mechanism to tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10395aa5",
   "metadata": {},
   "source": [
    "### 2.2.1 Training and Testing Data\n",
    "\n",
    "We will split the data into training and testing sets. The training set will be used to train the models, while the testing set will be used to evaluate their performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf2b52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (842, 21)\n",
      "X_test shape: (361, 21)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['deterioration_label']), df['deterioration_label'], test_size=0.3, random_state=42)\n",
    "\n",
    "# check the shape of the data\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# save the y_test\n",
    "y_test.to_csv('data/processed/y_test_ml.csv', index=False)\n",
    "\n",
    "# save X_train\n",
    "X_train.to_csv('data/processed/X_train_ml.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb55340b",
   "metadata": {},
   "source": [
    "### 2.2.2 Traditional Models\n",
    "\n",
    "We will start with setting up traditional machine learning models such as Random Forest, XGBoost, and Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d8a2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for modeling\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create directory for model storage if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Dictionary to store model results for later evaluation\n",
    "model_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcab52ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Random Forest model trained and saved!\n"
     ]
    }
   ],
   "source": [
    "# ---- Random Forest ----\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_train_preds = rf_model.predict(X_train)\n",
    "rf_test_preds = rf_model.predict(X_test)\n",
    "rf_test_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Store results\n",
    "model_results['random_forest'] = {\n",
    "    'train_preds': rf_train_preds,\n",
    "    'test_preds': rf_test_preds,\n",
    "    'test_proba': rf_test_proba\n",
    "}\n",
    "\n",
    "# Save the model\n",
    "with open('models/random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "\n",
    "print(\"Random Forest model trained and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a60e2b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n",
      "XGBoost model trained and saved!\n"
     ]
    }
   ],
   "source": [
    "# ---- XGBoost ----\n",
    "print(\"Training XGBoost model...\")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "xgb_train_preds = xgb_model.predict(X_train)\n",
    "xgb_test_preds = xgb_model.predict(X_test)\n",
    "xgb_test_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Store results\n",
    "model_results['xgboost'] = {\n",
    "    'train_preds': xgb_train_preds,\n",
    "    'test_preds': xgb_test_preds,\n",
    "    'test_proba': xgb_test_proba\n",
    "}\n",
    "\n",
    "# Save the model\n",
    "with open('models/xgboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "\n",
    "print(\"XGBoost model trained and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b969e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Neural Network model...\n",
      "Neural Network model trained and saved!\n"
     ]
    }
   ],
   "source": [
    "# ---- Neural Network ----\n",
    "print(\"Training Neural Network model...\")\n",
    "\n",
    "# Scale features for neural network\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define and train the neural network\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),  # Two hidden layers\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    batch_size='auto',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nn_train_preds = nn_model.predict(X_train_scaled)\n",
    "nn_test_preds = nn_model.predict(X_test_scaled)\n",
    "nn_test_proba = nn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Store results\n",
    "model_results['neural_network'] = {\n",
    "    'train_preds': nn_train_preds,\n",
    "    'test_preds': nn_test_preds,\n",
    "    'test_proba': nn_test_proba,\n",
    "    'scaler': scaler  # Save the scaler for future predictions\n",
    "}\n",
    "\n",
    "# Save the model and scaler\n",
    "with open('models/neural_network_model.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': nn_model,\n",
    "        'scaler': scaler\n",
    "    }, f)\n",
    "\n",
    "print(\"Neural Network model trained and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a62ef2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models trained and results saved for evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Save all model results for later evaluation\n",
    "with open('models/model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(model_results, f)\n",
    "\n",
    "print(\"All models trained and results saved for evaluation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba6b84f",
   "metadata": {},
   "source": [
    "### 2.2.3 Transformer-based Models\n",
    "\n",
    "#### 2.2.3.1 FT Transformer\n",
    "\n",
    "In this section, we will explore the use of FT Transformer model for tabular data. The FT Transformer model is a specialized transformer model that is designed to work with tabular data. It uses attention mechanisms to learn the relationships between different features in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4054645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: []\n",
      "Numerical columns: ['age', 'hear_rate', 'blood_pressure_sys', 'blood_pressure_dia', 'oxygen_saturation', 'temperature', 'respiratory_rate', 'has_stroke', 'has_diabetes', 'has_hypertension', 'has_cancer', 'has_heart attack', 'has_heart failure', 'has_copd', 'has_asthma', 'has_alzheimer', 'has_dementia', 'fatigue_level', 'activity_level', 'mental_health_level']\n",
      "Training FT Transformer model...\n",
      "Epoch 2/30, Loss: 0.1754\n",
      "Epoch 4/30, Loss: 0.0983\n",
      "Epoch 6/30, Loss: 0.0666\n",
      "Epoch 8/30, Loss: 0.0559\n",
      "Epoch 10/30, Loss: 0.0442\n",
      "Epoch 12/30, Loss: 0.0454\n",
      "Epoch 14/30, Loss: 0.0821\n",
      "Epoch 16/30, Loss: 0.0289\n",
      "Epoch 18/30, Loss: 0.0231\n",
      "Epoch 20/30, Loss: 0.0548\n",
      "Epoch 22/30, Loss: 0.0257\n",
      "Epoch 24/30, Loss: 0.0186\n",
      "Epoch 26/30, Loss: 0.0141\n",
      "Epoch 28/30, Loss: 0.0128\n",
      "Epoch 30/30, Loss: 0.0121\n",
      "FT Transformer model training complete!\n"
     ]
    }
   ],
   "source": [
    "# ---- FTTransformer Implementation ----\n",
    "import torch\n",
    "import numpy as np\n",
    "from tab_transformer_pytorch import FTTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "\n",
    "# Prepare categorical data (if any)\n",
    "categorical_dims = {}\n",
    "for col in categorical_cols:\n",
    "    X_train[col] = X_train[col].astype('category')\n",
    "    categorical_dims[col] = len(X_train[col].cat.categories)\n",
    "\n",
    "# Get categories for FTTransformer\n",
    "if len(categorical_cols) > 0:\n",
    "    categories = tuple([categorical_dims[col] for col in categorical_cols])\n",
    "else:\n",
    "    categories = tuple()  # Empty if no categorical columns\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train[numerical_cols].values)\n",
    "X_test_num = scaler.transform(X_test[numerical_cols].values)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "if len(categorical_cols) > 0:\n",
    "    X_train_cat = torch.tensor(X_train[categorical_cols].values, dtype=torch.long)\n",
    "    X_test_cat = torch.tensor(X_test[categorical_cols].values, dtype=torch.long)\n",
    "else:\n",
    "    X_train_cat = torch.zeros((X_train.shape[0], 0), dtype=torch.long)\n",
    "    X_test_cat = torch.zeros((X_test.shape[0], 0), dtype=torch.long)\n",
    "    \n",
    "X_train_num = torch.tensor(X_train_num, dtype=torch.float)\n",
    "X_test_num = torch.tensor(X_test_num, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float).reshape(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float).reshape(-1, 1)\n",
    "\n",
    "# Define FTTransformer model\n",
    "model = FTTransformer(\n",
    "    categories=categories,            # categories tuple from above\n",
    "    num_continuous=len(numerical_cols),  # number of numerical columns\n",
    "    dim=32,                           # embedding dimension\n",
    "    dim_out=1,                        # binary classification (0 or 1)\n",
    "    depth=6,                          # transformer layers\n",
    "    heads=8,                          # attention heads\n",
    "    attn_dropout=0.1,                 # dropout rate\n",
    "    ff_dropout=0.1                    # feed forward dropout\n",
    ")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "n_samples = X_train_num.shape[0]\n",
    "n_batches = n_samples // batch_size + (1 if n_samples % batch_size != 0 else 0)\n",
    "\n",
    "print(\"Training FT Transformer model...\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Create batches\n",
    "    indices = torch.randperm(n_samples)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        # Get batch indices\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, n_samples)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "        \n",
    "        # Get batch data\n",
    "        if len(categorical_cols) > 0:\n",
    "            X_cat_batch = X_train_cat[batch_indices]\n",
    "        else:\n",
    "            X_cat_batch = X_train_cat  # Empty tensor\n",
    "            \n",
    "        X_num_batch = X_train_num[batch_indices]\n",
    "        y_batch = y_train_tensor[batch_indices]\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_cat_batch, X_num_batch)\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print epoch statistics\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/n_batches:.4f}\")\n",
    "\n",
    "print(\"FT Transformer model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcaba54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FT Transformer model evaluated and saved!\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_proba = torch.sigmoid(model(X_test_cat, X_test_num)).numpy()\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# Store results\n",
    "model_results['ft_transformer'] = {\n",
    "    'test_preds': y_pred.flatten(),\n",
    "    'test_proba': y_pred_proba.flatten()\n",
    "}\n",
    "\n",
    "# Save the model and additional info\n",
    "model_save = {\n",
    "    'model': model.state_dict(),\n",
    "    'num_scaler': scaler,\n",
    "    'categorical_cols': categorical_cols,\n",
    "    'numerical_cols': numerical_cols\n",
    "}\n",
    "\n",
    "with open('models/ft_transformer_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_save, f)\n",
    "\n",
    "# Update all model results\n",
    "with open('models/model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(model_results, f)\n",
    "\n",
    "print(\"FT Transformer model evaluated and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d8625e",
   "metadata": {},
   "source": [
    "#### 2.2.3.2 Tab Transformer\n",
    "\n",
    "In this section, we will explore the use of TabTransformer model for tabular data. The TabTransformer model is a transformer-based architecture that is designed to work with tabular data. It uses self-attention mechanisms to capture relationships between features and can be used for both classification and regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "948367a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: []\n",
      "Numerical columns: ['age', 'hear_rate', 'blood_pressure_sys', 'blood_pressure_dia', 'oxygen_saturation', 'temperature', 'respiratory_rate', 'has_stroke', 'has_diabetes', 'has_hypertension', 'has_cancer', 'has_heart attack', 'has_heart failure', 'has_copd', 'has_asthma', 'has_alzheimer', 'has_dementia', 'fatigue_level', 'activity_level', 'mental_health_level']\n",
      "Training Tab Transformer model...\n",
      "Epoch 2/30, Loss: 0.4086\n",
      "Epoch 4/30, Loss: 0.0933\n",
      "Epoch 6/30, Loss: 0.0399\n",
      "Epoch 8/30, Loss: 0.0265\n",
      "Epoch 10/30, Loss: 0.0211\n",
      "Epoch 12/30, Loss: 0.0265\n",
      "Epoch 14/30, Loss: 0.0163\n",
      "Epoch 16/30, Loss: 0.0140\n",
      "Epoch 18/30, Loss: 0.0136\n",
      "Epoch 20/30, Loss: 0.0111\n",
      "Epoch 22/30, Loss: 0.0108\n",
      "Epoch 24/30, Loss: 0.0095\n",
      "Epoch 26/30, Loss: 0.0083\n",
      "Epoch 28/30, Loss: 0.0079\n",
      "Epoch 30/30, Loss: 0.0069\n",
      "Tab Transformer model training complete!\n"
     ]
    }
   ],
   "source": [
    "# ---- TabTransformer Implementation ----\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "import torch.nn as nn\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "\n",
    "# Prepare categorical data (if any)\n",
    "categorical_dims = {}\n",
    "for col in categorical_cols:\n",
    "    X_train[col] = X_train[col].astype('category')\n",
    "    categorical_dims[col] = len(X_train[col].cat.categories)\n",
    "\n",
    "# Get categories for FTTransformer\n",
    "if len(categorical_cols) > 0:\n",
    "    categories = tuple([categorical_dims[col] for col in categorical_cols])\n",
    "else:\n",
    "    categories = tuple()  # Empty if no categorical columns\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train[numerical_cols].values)\n",
    "X_test_num = scaler.transform(X_test[numerical_cols].values)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "if len(categorical_cols) > 0:\n",
    "    X_train_cat = torch.tensor(X_train[categorical_cols].values, dtype=torch.long)\n",
    "    X_test_cat = torch.tensor(X_test[categorical_cols].values, dtype=torch.long)\n",
    "else:\n",
    "    X_train_cat = torch.zeros((X_train.shape[0], 0), dtype=torch.long)\n",
    "    X_test_cat = torch.zeros((X_test.shape[0], 0), dtype=torch.long)\n",
    "    \n",
    "X_train_num = torch.tensor(X_train_num, dtype=torch.float)\n",
    "X_test_num = torch.tensor(X_test_num, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float).reshape(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float).reshape(-1, 1)\n",
    "\n",
    "# Define TabTransformer model\n",
    "model = TabTransformer(\n",
    "    categories=categories,            # categories tuple from above\n",
    "    num_continuous=len(numerical_cols),  # number of numerical columns\n",
    "    dim=32,                           # embedding dimension\n",
    "    dim_out=1,                        # binary classification (0 or 1)\n",
    "    depth=6,                          # transformer layers\n",
    "    heads=8,                          # attention heads\n",
    "    attn_dropout=0.1,                 # dropout rate\n",
    "    ff_dropout=0.1,                    # feed forward dropout\n",
    "    mlp_hidden_mults = (4, 2),          # relative multiples of each hidden dimension of the last mlp to logits\n",
    "    mlp_act = nn.ReLU(),\n",
    ")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "n_samples = X_train_num.shape[0]\n",
    "n_batches = n_samples // batch_size + (1 if n_samples % batch_size != 0 else 0)\n",
    "\n",
    "print(\"Training Tab Transformer model...\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Create batches\n",
    "    indices = torch.randperm(n_samples)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        # Get batch indices\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, n_samples)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "        \n",
    "        # Get batch data\n",
    "        if len(categorical_cols) > 0:\n",
    "            X_cat_batch = X_train_cat[batch_indices]\n",
    "        else:\n",
    "            X_cat_batch = X_train_cat  # Empty tensor\n",
    "            \n",
    "        X_num_batch = X_train_num[batch_indices]\n",
    "        y_batch = y_train_tensor[batch_indices]\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_cat_batch, X_num_batch)\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print epoch statistics\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/n_batches:.4f}\")\n",
    "\n",
    "print(\"Tab Transformer model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1145e944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tab Transformer model evaluated and saved!\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_proba = torch.sigmoid(model(X_test_cat, X_test_num)).numpy()\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# Store results\n",
    "model_results['tab_transformer'] = {\n",
    "    'test_preds': y_pred.flatten(),\n",
    "    'test_proba': y_pred_proba.flatten()\n",
    "}\n",
    "\n",
    "# Save the model and additional info\n",
    "model_save = {\n",
    "    'model': model.state_dict(),\n",
    "    'num_scaler': scaler,\n",
    "    'categorical_cols': categorical_cols,\n",
    "    'numerical_cols': numerical_cols\n",
    "}\n",
    "\n",
    "with open('models/tab_transformer_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_save, f)\n",
    "\n",
    "# Update all model results\n",
    "with open('models/model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(model_results, f)\n",
    "\n",
    "print(\"Tab Transformer model evaluated and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742c9dbb",
   "metadata": {},
   "source": [
    "Now all the models are trained, and their evaluation results are saved in the local directory which will be further investigated in the next section. For the next part we will look into Natural Language Processing (NLP) tasks such as sentiment analysis, classification, and clinical text interpretation using specialized language models (SLMs). We will also explore the use of transformer-based models for these tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
